{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49adc746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Baseline] Agent prior AUC: 0.8567\n",
      "[Baseline] Top-10% | k=1301 | AUC=0.857 | P=0.4750 | R=0.4972 | F1=0.4858\n",
      "[Baseline] Top-20% | k=2601 | AUC=0.857 | P=0.4198 | R=0.8785 | F1=0.5682\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix, classification_report\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "user = \"root\"\n",
    "password = quote_plus(\"Yangsijie0819$\")  # 避免密码里有 @ : / 等特殊字符导致连接串坏掉\n",
    "host = \"127.0.0.1\"\n",
    "port = 3306\n",
    "db = \"aidev\"\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"mysql+pymysql://{user}:{password}@{host}:{port}/{db}?charset=utf8mb4\",\n",
    "    pool_pre_ping=True,\n",
    ")\n",
    "\n",
    "# 2) 读取 RQ3 数据集（只含早期可见特征 + 标签）\n",
    "df = pd.read_sql(\"\"\"\n",
    "SELECT pr_id, repo_id, agent, scenario_label, state, high_cost\n",
    "FROM pr_rq3_dataset;\n",
    "\"\"\", engine)\n",
    "\n",
    "# 3) 基本清理：state 不再需要，可以不 dropna 它\n",
    "df = df.dropna(subset=[\"repo_id\", \"agent\", \"scenario_label\", \"high_cost\"]).copy()\n",
    "df[\"high_cost\"] = df[\"high_cost\"].astype(int)\n",
    "\n",
    "# 4) 只保留 agent + scenario_label\n",
    "X = df[[\"agent\", \"scenario_label\"]]\n",
    "y = df[\"high_cost\"]\n",
    "groups = df[\"repo_id\"]\n",
    "\n",
    "# 5) 按 repo 分组切分\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "# ===== Baseline: agent prior risk (train-only, no leakage) =====\n",
    "df_train = df.iloc[train_idx].copy()\n",
    "df_test  = df.iloc[test_idx].copy()\n",
    "\n",
    "global_rate = df_train[\"high_cost\"].mean()\n",
    "\n",
    "agent_rate = df_train.groupby(\"agent\")[\"high_cost\"].mean()\n",
    "proba_agent_prior = df_test[\"agent\"].map(agent_rate).fillna(global_rate).to_numpy()\n",
    "\n",
    "prid_test = df_test[\"pr_id\"].to_numpy()  # 你 Top-k tie-break 需要\n",
    "y_test_np = df_test[\"high_cost\"].to_numpy()\n",
    "\n",
    "print(\"\\n[Baseline] Agent prior AUC:\", round(roc_auc_score(y_test_np, proba_agent_prior), 4))\n",
    "for ar in [0.10, 0.20]:\n",
    "    out = eval_topk(ar, proba_agent_prior, y_test_np, prid_test)\n",
    "    print(\n",
    "        f\"[Baseline] Top-{int(ar*100)}% | k={out['k']} | \"\n",
    "        f\"AUC={out['AUC']:.3f} | P={out['precision']:.4f} | R={out['recall']:.4f} | F1={out['f1']:.4f}\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c801cc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_test: 13002\n",
      "test_repo_unique: 562\n",
      "pos_rate_test: 0.09560067681895093\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 新增三种\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# sanity check: split 是否固定\n",
    "print(\"n_test:\", len(test_idx))\n",
    "print(\"test_repo_unique:\", df.iloc[test_idx][\"repo_id\"].nunique())\n",
    "print(\"pos_rate_test:\", df.iloc[test_idx][\"high_cost\"].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55ba48ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC (agent only): 0.8567\n",
      "AUC (scenario only): 0.6654\n",
      "AUC (agent + scenario): 0.8284\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def auc_on_cols(cols):\n",
    "    Xtr = df.iloc[train_idx][cols]\n",
    "    Xte = df.iloc[test_idx][cols]\n",
    "    ytr = df.iloc[train_idx][\"high_cost\"]\n",
    "    yte = df.iloc[test_idx][\"high_cost\"]\n",
    "\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[(\"cat\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\"), cols)],\n",
    "        remainder=\"drop\",\n",
    "    )\n",
    "    clf = LogisticRegression(max_iter=2000, class_weight=\"balanced\", C=10.0)\n",
    "\n",
    "    m = Pipeline([(\"preprocess\", preprocess), (\"clf\", clf)])\n",
    "    m.fit(Xtr, ytr)\n",
    "\n",
    "    proba = m.predict_proba(Xte)[:, 1]\n",
    "    return roc_auc_score(yte, proba)\n",
    "\n",
    "auc_agent = auc_on_cols([\"agent\"])\n",
    "auc_scen  = auc_on_cols([\"scenario_label\"])\n",
    "auc_both  = auc_on_cols([\"agent\", \"scenario_label\"])\n",
    "\n",
    "print(\"AUC (agent only):\", round(auc_agent, 4))\n",
    "print(\"AUC (scenario only):\", round(auc_scen, 4))\n",
    "print(\"AUC (agent + scenario):\", round(auc_both, 4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c36a0a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Repeated GSS] runs used: 30/30\n",
      "[Repeated GSS] AUC mean±std: 0.7974 ± 0.0395\n",
      "[Repeated GSS] Top-10% P/R/F1 mean: 0.5893 0.2685 0.3511\n",
      "[Repeated GSS] Top-20% P/R/F1 mean: 0.5756 0.4869 0.506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def fit_predict_proba(train_idx, test_idx, cat_cols):\n",
    "    Xtr = df.iloc[train_idx][cat_cols]\n",
    "    Xte = df.iloc[test_idx][cat_cols]\n",
    "    ytr = df.iloc[train_idx][\"high_cost\"]\n",
    "    yte = df.iloc[test_idx][\"high_cost\"].to_numpy()\n",
    "    prid = df.iloc[test_idx][\"pr_id\"].to_numpy()\n",
    "\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[(\"cat\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\"), cat_cols)],\n",
    "        remainder=\"drop\",\n",
    "    )\n",
    "    clf = LogisticRegression(max_iter=2000, class_weight=\"balanced\", C=1.0)\n",
    "    model = Pipeline([(\"preprocess\", preprocess), (\"clf\", clf)])\n",
    "    model.fit(Xtr, ytr)\n",
    "\n",
    "    proba = model.predict_proba(Xte)[:, 1]\n",
    "    return yte, proba, prid\n",
    "\n",
    "# ===== Repeated repo-level splits =====\n",
    "cat_cols = [\"agent\", \"scenario_label\"]  # 或 [\"agent\"] 看你主模型\n",
    "groups = df[\"repo_id\"].to_numpy()\n",
    "\n",
    "aucs, p10s, r10s, f10s, p20s, r20s, f20s = [], [], [], [], [], [], []\n",
    "\n",
    "n_runs = 30\n",
    "for rs in range(n_runs):\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=rs)\n",
    "    tr, te = next(gss.split(df, df[\"high_cost\"], groups=groups))\n",
    "\n",
    "    yte, proba, prid = fit_predict_proba(tr, te, cat_cols)\n",
    "\n",
    "    # 跳过“测试集单类”的极端情况（通常很少）\n",
    "    if len(np.unique(yte)) < 2:\n",
    "        continue\n",
    "\n",
    "    aucs.append(roc_auc_score(yte, proba))\n",
    "    out10 = eval_topk(0.10, proba, yte, prid)\n",
    "    out20 = eval_topk(0.20, proba, yte, prid)\n",
    "\n",
    "    p10s.append(out10[\"precision\"]); r10s.append(out10[\"recall\"]); f10s.append(out10[\"f1\"])\n",
    "    p20s.append(out20[\"precision\"]); r20s.append(out20[\"recall\"]); f20s.append(out20[\"f1\"])\n",
    "\n",
    "print(f\"\\n[Repeated GSS] runs used: {len(aucs)}/{n_runs}\")\n",
    "print(\"[Repeated GSS] AUC mean±std:\", round(np.mean(aucs), 4), \"±\", round(np.std(aucs), 4))\n",
    "print(\"[Repeated GSS] Top-10% P/R/F1 mean:\",\n",
    "      round(np.mean(p10s), 4), round(np.mean(r10s), 4), round(np.mean(f10s), 4))\n",
    "print(\"[Repeated GSS] Top-20% P/R/F1 mean:\",\n",
    "      round(np.mean(p20s), 4), round(np.mean(r20s), 4), round(np.mean(f20s), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3de90fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.8272\n",
      "Test F1: 0.7146\n",
      "Confusion matrix:\n",
      " [[11340   419]\n",
      " [  319   924]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.9644    0.9685     11759\n",
      "           1     0.6880    0.7434    0.7146      1243\n",
      "\n",
      "    accuracy                         0.9432     13002\n",
      "   macro avg     0.8303    0.8539    0.8416     13002\n",
      "weighted avg     0.9454    0.9432    0.9442     13002\n",
      "\n",
      "\n",
      "Top 20 features by |coef|:\n",
      "                          feature      coef  abs_coef\n",
      "scenario_label_S2_Human_coedited  2.847765  2.847765\n",
      "scenario_label_S1_Human_reviewed  2.716060  2.716060\n",
      "              agent_OpenAI_Codex -1.161978  1.161978\n",
      "                    agent_Cursor  0.826845  0.826845\n",
      "                   agent_Copilot  0.816780  0.816780\n",
      "                     agent_Devin  0.815365  0.815365\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 6) One-hot + Logistic Regression（把 state 从 cat_cols 里删掉）\n",
    "cat_cols = [\"agent\", \"scenario_label\"]\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\"), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
    "\n",
    "model = Pipeline(steps=[(\"preprocess\", preprocess), (\"clf\", clf)])\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 7) 评估\n",
    "proba = model.predict_proba(X_test)[:, 1]\n",
    "pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "auc = roc_auc_score(y_test, proba)\n",
    "f1 = f1_score(y_test, pred)\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "\n",
    "print(\"Test AUC:\", round(auc, 4))\n",
    "print(\"Test F1:\", round(f1, 4))\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, pred, digits=4))\n",
    "\n",
    "# 8) 输出最重要特征\n",
    "ohe = model.named_steps[\"preprocess\"].named_transformers_[\"cat\"]\n",
    "feature_names = ohe.get_feature_names_out(cat_cols)\n",
    "coefs = model.named_steps[\"clf\"].coef_[0]\n",
    "\n",
    "imp = (\n",
    "    pd.DataFrame({\"feature\": feature_names, \"coef\": coefs})\n",
    "    .assign(abs_coef=lambda d: d[\"coef\"].abs())\n",
    "    .sort_values(\"abs_coef\", ascending=False)\n",
    "    .head(20)\n",
    ")\n",
    "\n",
    "print(\"\\nTop 20 features by |coef|:\\n\", imp.to_string(index=False))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a9bb885",
   "metadata": {},
   "outputs": [],
   "source": [
    "prid_test = df.iloc[test_idx][\"pr_id\"].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8679e98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10% | k=1301 | pos_rate=0.1001 | AUC=0.827 | P=0.6941 | R=0.7265 | F1=0.7099\n",
      "Top-20% | k=2601 | pos_rate=0.2000 | AUC=0.827 | P=0.4079 | R=0.8536 | F1=0.5520\n"
     ]
    }
   ],
   "source": [
    "# 按 Top-K 评估\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def eval_topk(alert_rate: float, proba, y_test, prid_test):\n",
    "    n = len(proba)\n",
    "    k = int(np.ceil(alert_rate * n))\n",
    "\n",
    "    # 可复现排序：proba 高优先；并列用 pr_id 小的优先\n",
    "    order = np.lexsort((prid_test, -proba))\n",
    "    pred_k = np.zeros(n, dtype=int)\n",
    "    pred_k[order[:k]] = 1\n",
    "\n",
    "    out = {\n",
    "        \"alert_rate\": alert_rate,\n",
    "        \"k\": k,\n",
    "        \"predicted_positive_rate\": pred_k.mean(),\n",
    "        \"AUC\": roc_auc_score(y_test, proba),\n",
    "        \"precision\": precision_score(y_test, pred_k, zero_division=0),\n",
    "        \"recall\": recall_score(y_test, pred_k, zero_division=0),\n",
    "        \"f1\": f1_score(y_test, pred_k, zero_division=0),\n",
    "    }\n",
    "    return out\n",
    "\n",
    "for ar in [0.10, 0.20]:  # 想加 0.05 就改成 [0.05, 0.10, 0.20]\n",
    "    out = eval_topk(ar, proba, y_test, prid_test)\n",
    "    print(\n",
    "        f\"Top-{int(ar*100)}% | k={out['k']} | pos_rate={out['predicted_positive_rate']:.4f} | \"\n",
    "        f\"AUC={out['AUC']:.3f} | P={out['precision']:.4f} | R={out['recall']:.4f} | F1={out['f1']:.4f}\"\n",
    "    )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
